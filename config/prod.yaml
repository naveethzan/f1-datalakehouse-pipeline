# Production settings for AWS deployment
environment: "production"

# AWS Services Configuration (same for both local and production)
aws_services:
  region: "us-east-1"
  profile: null  # Use IAM roles in production
  s3_bucket: "f1-data-lake-naveeth"
  cloudwatch_namespace: "F1Pipeline"
  glue_catalog_database: "f1_data_catalog"
  iam_role: "F1-DataPipeline-Role"

s3:
  bucket_name: "f1-data-lake-naveeth"
  bronze_prefix: "bronze/"
  silver_prefix: "silver/"
  gold_prefix: "gold/"

api:
  base_url: "https://api.openf1.org/v1"
  rate_limit_per_second: 5  # Higher rate limit for production
  rate_limit_seconds: 0.1
  max_retries: 5  # More retries for production reliability
  timeout_seconds: 60  # Longer timeout for production

session_types:
  - "Qualifying"
  - "Race"

target_year: 2025

parquet:
  compression: "snappy"
  row_group_size: 100000  # Larger row groups for production
  use_dictionary: true
  write_statistics: true
  coerce_timestamps: "ms"
  allow_truncated_timestamps: true

cloudwatch:
  namespace: "F1Pipeline/Production"
  environment_dimension: "prod"
  enabled: true

lineage:
  enabled: true
  s3_prefix: "lineage/"
  events_prefix: "events/"
  summaries_prefix: "summaries/"
  producer: "f1-data-pipeline/production"
  schema_url: "https://openlineage.io/spec/1-0-5/OpenLineage.json#/$defs/RunEvent"

logging:
  level: "WARNING"  # Less verbose logging in production
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  include_timestamp: true
  log_file: null

data_validation:
  enabled: true
  fail_on_critical_errors: true
  warning_threshold_percent: 30  # Stricter validation in production

spark:
  app_name: "F1-Data-Pipeline-Prod"
  log_level: "WARN"  # Less verbose Spark logging in production
  master_url: null  # Not used in AWS Glue

iceberg:
  catalog_type: "glue"
  warehouse_path: "s3://f1-data-lake-naveeth/iceberg-warehouse/"

# Silver layer specific configuration
silver:
  database_name: "f1_silver_db"
  target_file_size_mb: 256  # Larger files for production
  large_table_file_size_mb: 512
  maintenance:
    snapshot_retention_days: 14  # Longer retention for production
    compaction_enabled: true
    orphan_file_cleanup_enabled: true

# Gold layer specific configuration
gold:
  database_name: "f1_gold_db"
  target_file_size_mb: 512  # Larger files for production analytics
  session_specific_processing: true
  tables:
    - "driver_performance_summary_qualifying"
    - "driver_performance_summary_race"
    - "championship_tracker"
    - "team_strategy_analysis"
    - "race_weekend_insights"
  maintenance:
    snapshot_retention_days: 60  # Much longer retention for production
    compaction_enabled: true
    orphan_file_cleanup_enabled: true
    optimize_schedule: "daily"  # More frequent optimization in production

# Environment-Specific Task Configurations
tasks:
  silver_transformation:
    development:
      script_path: "jobs/f1_bronze_to_silver_transform.py"
      spark_conf:
        spark.sql.adaptive.enabled: "true"
        spark.sql.adaptive.coalescePartitions.enabled: "true"
        spark.sql.adaptive.skewJoin.enabled: "true"
        spark.sql.adaptive.localShuffleReader.enabled: "true"
        spark.serializer: "org.apache.spark.serializer.KryoSerializer"
        spark.sql.execution.arrow.pyspark.enabled: "true"
        spark.sql.execution.arrow.maxRecordsPerBatch: "10000"
        spark.sql.adaptive.advisoryPartitionSizeInBytes: "128MB"
        spark.eventLog.enabled: "true"
        spark.eventLog.dir: "s3://f1-data-lake-naveeth/spark-logs"
    production:
      job_name: "f1-bronze-to-silver-transform-prod"
      script_location: "s3://f1-data-lake-naveeth/jobs/f1_bronze_to_silver_transform.py"
      iam_role_name: "F1-DataPipeline-Role"
      glue_version: "4.0"
      number_of_workers: 20
      worker_type: "G.2X"
      max_retries: 3
      timeout: 120
      retries: 3
      retry_delay: "00:10:00"

  gold_transformation:
    development:
      script_path: "jobs/f1_silver_to_gold_transform.py"
      spark_conf:
        spark.sql.adaptive.enabled: "true"
        spark.sql.adaptive.coalescePartitions.enabled: "true"
        spark.sql.adaptive.skewJoin.enabled: "true"
        spark.sql.adaptive.localShuffleReader.enabled: "true"
        spark.serializer: "org.apache.spark.serializer.KryoSerializer"
        spark.sql.execution.arrow.pyspark.enabled: "true"
        spark.sql.execution.arrow.maxRecordsPerBatch: "10000"
        spark.sql.adaptive.advisoryPartitionSizeInBytes: "256MB"
        spark.eventLog.enabled: "true"
        spark.eventLog.dir: "s3://f1-data-lake-naveeth/spark-logs"
    production:
      job_name: "f1-silver-to-gold-transform-prod"
      script_location: "s3://f1-data-lake-naveeth/jobs/f1_silver_to_gold_transform.py"
      iam_role_name: "F1-DataPipeline-Role"
      glue_version: "4.0"
      number_of_workers: 10
      worker_type: "G.4X"
      max_retries: 3
      timeout: 180
      retries: 3
      retry_delay: "00:10:00"

# Airflow-specific settings for production (AWS MWAA)
airflow:
  dag_settings:
    max_active_runs: 3  # Allow more concurrent runs in production
    retries: 3  # More retries for production reliability
    retry_delay_minutes: 10  # Longer delay between retries
    catchup: false
  variables:
    f1_config_path: "/opt/airflow/config/prod.yaml"
    s3_bucket: "f1-data-lake-naveeth"
    target_year: 2025
  environment:
    executor: "CeleryExecutor"  # Production executor
    max_workers: 5  # More workers for production
    parallelism: 10  # Higher parallelism for production
    dag_concurrency: 16  # Higher concurrency for production
    max_active_tasks_per_dag: 16  # More active tasks per DAG
